{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from nltk import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf74e30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T19:26:17.134207Z",
     "start_time": "2022-02-16T19:26:17.032760Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4t/444kxfjn18909r8jzgjlvxk00000gn/T/ipykernel_21422/2108289622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/judge_1377884607_tweet_product_company.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/judge_1377884607_tweet_product_company.csv')\n",
    "df.head(-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c0424d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T19:26:35.381342Z",
     "start_time": "2022-02-16T19:26:35.372146Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4t/444kxfjn18909r8jzgjlvxk00000gn/T/ipykernel_21422/3771845804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emotion_in_tweet_is_directed_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bef4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = pos_neg[pos_neg['is_there_an_emotion_directed_at_a_brand_or_product'] != \"No emotion toward brand or product\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952e439",
   "metadata": {},
   "source": [
    "# Heavily imbalanced datset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9364c",
   "metadata": {},
   "source": [
    "### Positive / Negative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e002fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = pos_neg.drop('emotion_in_tweet_is_directed_at', axis=1)\n",
    "pos_neg = pos_neg.rename(columns={'tweet_text':'text', 'is_there_an_emotion_directed_at_a_brand_or_product':'target'})\n",
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ats_and_hashtags(text):\n",
    "    entity_prefixes = ['@','#','ï¿½']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32232c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text'] = pos_neg['text'].map(remove_ats_and_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.replace({'Negative emotion' : 0, 'Positive emotion' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba15cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text'] = pos_neg['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c203fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d58da",
   "metadata": {},
   "source": [
    "### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ee6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_tokenized'] = pos_neg['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_neg['text_tokenized'].explode()\n",
    "pos_neg_freq_dist = FreqDist(pos_neg['text_tokenized'].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_20(freq_dist, title):\n",
    "\n",
    "    # Extract data for plotting\n",
    "    top_20 = list(zip(*freq_dist.most_common(20)))\n",
    "    tokens = top_20[0]\n",
    "    counts = top_20[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "#     ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f72c27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_top_20(pos_neg_freq_dist, \"Top 20 Word Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f930408",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pos_neg.drop(['target'], axis=1)\n",
    "y = pos_neg['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724da94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1493f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c88ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64665b1",
   "metadata": {},
   "source": [
    "### Build a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d66bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(k_neighbors=1)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49936cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(X_train_resampled, columns=tfidf.get_feature_names()).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57750d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MultinomialNB classifier\n",
    "baseline_model = MultinomialNB()\n",
    "baseline_model.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "baseline_cv = cross_val_score(baseline_model, X_train_resampled, y_train_resampled)\n",
    "baseline_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf9b20",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "new_stops = ('quot', 'rt', 'i')\n",
    "stopwords_list += list(new_stops)\n",
    "\n",
    "def remove_stopwords(token_list):\n",
    "    \"\"\"\n",
    "    Given a list of tokens, return a list where the tokens\n",
    "    that are also present in stopwords_list have been\n",
    "    removed\n",
    "    \"\"\"\n",
    "    stops_rmv_list = [token for token in token_list if token not in stopwords_list]\n",
    "    return stops_rmv_list\n",
    "\n",
    "X_train[\"text_tokenized_without_stopwords\"] = X_train['text_tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9669c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=500, stop_words=stopwords_list)\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8eda8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(k_neighbors=5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MultinomialNB classifier\n",
    "stop_words_removed_model = MultinomialNB()\n",
    "stop_words_removed_model.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "stop_words_removed_cv = cross_val_score(stop_words_removed_model, X_train_resampled, y_train_resampled)\n",
    "stop_words_removed_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de073d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "stop_words_removed_preds = stop_words_removed_model.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, stop_words_removed_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ed661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbf015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "knn_5_cv = cross_val_score(knn, X_train_resampled, y_train_resampled)\n",
    "knn_5_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198d021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN (5) :         \", knn_5_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d885a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "knn_5_preds = knn_5.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, knn_5_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa60993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "knn_3_cv = cross_val_score(knn, X_train_resampled, y_train_resampled)\n",
    "knn_3_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de71dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN (5):          \", knn_5_cv.mean())\n",
    "print(\"KNN (3):          \", knn_10_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "knn_3_preds = knn_3.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, knn_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f607bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(knn_3, X_test_vectorized, y_test, cmap=plt.cm.Reds)\n",
    "plt.grid(False) # removes the annoying grid lines from plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN:              \", knn_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cd8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0929f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80e994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cefbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([a-z]{2,})\"\n",
    "regex_tokenizer = RegexpTokenizer(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_regex_tokenized'] = [regex_tokenizer.tokenize(text) for text in pos_neg['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4cbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_regex_tokenized'] = [' '.join(text) for text in pos_neg['text_regex_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4390d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8513e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088598d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3e939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text'] = [regex_tokenizer.tokenize(text) for text in X_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"text\"] = X_train['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2618322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmer.lemmatize(word) for word in text]\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919c6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30be724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def snow_stem_text(text):\n",
    "    return [snow_stemmer.stem(word) for word in text]\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(snow_stem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fac097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text'] = [' '.join(text) for text in X_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2cf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6e215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae2bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5c0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd161eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
