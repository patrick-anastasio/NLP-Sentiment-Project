{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from nltk import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a1748b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T19:26:17.134207Z",
     "start_time": "2022-02-16T19:26:17.032760Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4t/444kxfjn18909r8jzgjlvxk00000gn/T/ipykernel_21422/2108289622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/judge_1377884607_tweet_product_company.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/judge_1377884607_tweet_product_company.csv')\n",
    "df.head(-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75894a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T19:26:35.381342Z",
     "start_time": "2022-02-16T19:26:35.372146Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4t/444kxfjn18909r8jzgjlvxk00000gn/T/ipykernel_21422/3771845804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emotion_in_tweet_is_directed_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9440dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = pos_neg[pos_neg['is_there_an_emotion_directed_at_a_brand_or_product'] != \"No emotion toward brand or product\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa862b3d",
   "metadata": {},
   "source": [
    "# Heavily imbalanced datset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63191076",
   "metadata": {},
   "source": [
    "### Positive / Negative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = pos_neg.drop('emotion_in_tweet_is_directed_at', axis=1)\n",
    "pos_neg = pos_neg.rename(columns={'tweet_text':'text', 'is_there_an_emotion_directed_at_a_brand_or_product':'target'})\n",
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ats_and_hashtags(text):\n",
    "    entity_prefixes = ['@','#','ï¿½']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text'] = pos_neg['text'].map(remove_ats_and_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c076497",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.replace({'Negative emotion' : 0, 'Positive emotion' : 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text'] = pos_neg['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3cf6e",
   "metadata": {},
   "source": [
    "### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297bd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_tokenized'] = pos_neg['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de068c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2434d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_neg['text_tokenized'].explode()\n",
    "pos_neg_freq_dist = FreqDist(pos_neg['text_tokenized'].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_20(freq_dist, title):\n",
    "\n",
    "    # Extract data for plotting\n",
    "    top_20 = list(zip(*freq_dist.most_common(20)))\n",
    "    tokens = top_20[0]\n",
    "    counts = top_20[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "#     ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f0e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_top_20(pos_neg_freq_dist, \"Top 20 Word Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe85914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pos_neg.drop(['target'], axis=1)\n",
    "y = pos_neg['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9bd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29f5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04014d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e7080dd",
   "metadata": {},
   "source": [
    "### Build a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c54f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(k_neighbors=1)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03baba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00160684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(X_train_resampled, columns=tfidf.get_feature_names()).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MultinomialNB classifier\n",
    "baseline_model = MultinomialNB()\n",
    "baseline_model.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "baseline_cv = cross_val_score(baseline_model, X_train_resampled, y_train_resampled)\n",
    "baseline_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3d7ec",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "new_stops = ('quot', 'rt', 'i')\n",
    "stopwords_list += list(new_stops)\n",
    "\n",
    "def remove_stopwords(token_list):\n",
    "    \"\"\"\n",
    "    Given a list of tokens, return a list where the tokens\n",
    "    that are also present in stopwords_list have been\n",
    "    removed\n",
    "    \"\"\"\n",
    "    stops_rmv_list = [token for token in token_list if token not in stopwords_list]\n",
    "    return stops_rmv_list\n",
    "\n",
    "X_train[\"text_tokenized_without_stopwords\"] = X_train['text_tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01564ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=500, stop_words=stopwords_list)\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['text'])\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744a768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(k_neighbors=5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MultinomialNB classifier\n",
    "stop_words_removed_model = MultinomialNB()\n",
    "stop_words_removed_model.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "stop_words_removed_cv = cross_val_score(stop_words_removed_model, X_train_resampled, y_train_resampled)\n",
    "stop_words_removed_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "stop_words_removed_preds = stop_words_removed_model.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, stop_words_removed_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2866a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4bad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a42e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "knn_5_cv = cross_val_score(knn, X_train_resampled, y_train_resampled)\n",
    "knn_5_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d8099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN (5) :         \", knn_5_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "knn_5_preds = knn_5.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, knn_5_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc5f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7adbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_train_resampled, y_train_resampled)\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "knn_3_cv = cross_val_score(knn, X_train_resampled, y_train_resampled)\n",
    "knn_3_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dabe75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN (5):          \", knn_5_cv.mean())\n",
    "print(\"KNN (3):          \", knn_10_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.fit_transform(X_test['text'])\n",
    "knn_3_preds = knn_3.predict(X_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, knn_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(knn_3, X_test_vectorized, y_test, cmap=plt.cm.Reds)\n",
    "plt.grid(False) # removes the annoying grid lines from plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb79317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline:         \", baseline_cv.mean())\n",
    "print(\"Stopwords removed:\", stop_words_removed_cv.mean())\n",
    "print(\"KNN:              \", knn_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1536bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad499611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960207d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c914f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([a-z]{2,})\"\n",
    "regex_tokenizer = RegexpTokenizer(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a851d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_regex_tokenized'] = [regex_tokenizer.tokenize(text) for text in pos_neg['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e74b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg['text_regex_tokenized'] = [' '.join(text) for text in pos_neg['text_regex_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325edab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac46e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab0ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa9436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0959a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text'] = [regex_tokenizer.tokenize(text) for text in X_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"text\"] = X_train['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmer.lemmatize(word) for word in text]\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf98d724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def snow_stem_text(text):\n",
    "    return [snow_stemmer.stem(word) for word in text]\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(snow_stem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd5826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['text'] = [' '.join(text) for text in X_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a184b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f7295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7216f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252aa0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
